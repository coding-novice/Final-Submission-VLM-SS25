# Final-Submission-VLM-SS25
Master Seminar Submission for AI in Vision-Language Models in Medical Imaging.

# General Structure of the Repository

The repository contains the following folders:

1) Presentation
- Presentation of the Nature Paper "Detecting hallucinations in large language models using semantic entropy" by Farquhar et al.
    S. Farquhar, J. Kossen, L. Kuhn, and Y. Gal, “Detecting hallucinations in large language models using semantic
    entropy,” Nature, vol. 630, no. 8017, pp. 625–630, Jun. 2024, doi: 10.1038/s41586-024-07421-0.

2) Poster "A Comparative Study of VLMs for Medical Image Analysis: CheXagent and MAIRA-2" for comparison of MAIRA-2 and CheXagent

3) Code that was used to gather and evaluate the data in the Poster. The code within this repository was used to obtain results on MAIRA-2. For code used to obtain the results on CheXagent, please see the repository of Linfeng Guo.


# Details regarding the Code

The directory `code` contains the following files:

## `run_MAIRA2_used_outputs.sbatch`

- Running this .sbatch file produces all model outputs that were evaluated and directly used for the poster content.
- **How to run**: 
    - Within the sbatch file, please adjust the paths after "source" and "conda activate" to match the configuration on your machine.
    - Please also read the instructions under the section `MAIRA2.py` before running the code.

## `run_MAIRA2_extended_outputs.sbatch`

- Running this .sbatch file produces a more extensive selection of model outputs that also include the outputs generated by running `run_MAIRA2_used_outputs.sbatch`. While the results were used when evaluating the performance of MAIRA-2, they are not directly part of the results on the poster.
- **How to run**: 
    - Within the sbatch file, please adjust the paths after "source" and "conda activate" to match the configuration on your machine.
    - Please also read the instructions under the section `MAIRA2.py` before running the code.

## `maira2_env.yml`

- This YAML file reflects the environment that was used to run all of the code within this repository. You can use it to set up an environment that is suitable to run the code and reproduce the results on the poster.

## `xray_image_processing.py`

- This code was used to perform the processing of the chest x-ray imaging data, as indicated in the methods section of the poster. Please note the following:
1) The processed imaging data was only used for the task "Classification: Healthy vs. Unhealthy" in the poster. The portrayed results of the task "Localization: given Disease" are from MAIRA-2 prompts using unprocessed imaging data.
2) The brain MRI imaging data was not processed and always used in unprocessed format.


## `evaluate_metrics_Acc_F1.py`

- This code was used to calculate the results in the task "Classification: Healthy vs. Unhealthy", which was portrayed in the poster.

## `calculate_map.py`

- This code was used to calculate the results in the task "Localization: given Disease", which was portrayed in the poster.

## `MAIRA2.py`

- This is the code that is being executed by the two sbatch files.
- The code expects the file structure portrayed below. Please ensure the input data is in the correct location.

<project-root>/
├── MAIRA2.py
├── in/                 # Input data (user-provided)
│ ├── dataset/
│ │ ├── chest_xrays/
│ │ │ └── images/       # chest X-ray images in .png format
│ │ └── nova_brain/
│ │ └── images/         # brain MRI images in .png format
│ └── dataset_processed/ 
│ ├── processed_chest_with_bars/    # processed chest X-ray images (with black bars) in .png format
│ └── processed_chest_no_bars/      # processed chest X-ray images (with no bars) in .png format
├── out/                            # this is where the outputs of the code will be saved (.csv and .json)
└── slurm_output/                   # job-submission scripts will be saved here, when running the .sbatch files